<!DOCTYPE html  <!--
  - custom css link
  -->
  <link rel="stylesheet" href="./assets/css/style.css?v=2024011308">

  <!--
  - google font link
  --> lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Stefano Berti</title>

  <!--
    - favicon
  -->
  <link rel="shortcut icon" href="./assets/images/logo.ico" type="image/x-icon">

  <!--
    - custom css link
  -->
  <link rel="stylesheet" href="./assets/css/style.css?v=2024011307">

  <!--
    - google font link
  -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600&display=swap" rel="stylesheet">

  <!--
    - MIDI player scripts
  -->
  <script src="https://unpkg.com/tone@14.7.58/build/Tone.js"></script>
  <script src="https://unpkg.com/@magenta/music@1.21.0/es6/core.js"></script>
  <script src="https://unpkg.com/html-midi-player@1.5.0"></script>
</head>

<body>

  <!--
    - #MAIN
  -->

  <main>

    <!--
      - #SIDEBAR
    -->

    <aside class="sidebar" data-sidebar>

      <div class="sidebar-info">

        <figure class="avatar-box">
          <img src="./assets/images/my-avatar.jpg" alt="Stefano Berti" width="80" class="publication-img-clickable" data-popup-img="./assets/images/my-avatar.jpg">
        </figure>

        <div class="info-content">
          <h1 class="name" title="Stefano Berti">Stefano Berti</h1>

          <p class="title">PhD student</p>
        </div>

        <button class="info_more-btn" data-sidebar-btn>
          <span>Show Contacts</span>

          <ion-icon name="chevron-down"></ion-icon>
        </button>

      </div>

      <div class="sidebar-info_more">

        <div class="separator"></div>

        <ul class="contacts-list">

          <li class="contact-item">

            <div class="icon-box">
              <ion-icon name="mail-outline"></ion-icon>
            </div>

            <div class="contact-info">
              <p class="contact-title">Email</p>

              <a href="mailto:berti.ste@hotmail.it" class="contact-link">berti.ste@hotmail.it</a>
            </div>

          </li>

          <li class="contact-item">

            <div class="icon-box">
              <ion-icon name="phone-portrait-outline"></ion-icon>
            </div>

            <div class="contact-info">
              <p class="contact-title">Phone</p>

              <a href="tel:+393408580424" class="contact-link">+39 340 858 0424</a>
            </div>

          </li>

          <li class="contact-item">

            <div class="icon-box">
              <ion-icon name="calendar-outline"></ion-icon>
            </div>

            <div class="contact-info">
              <p class="contact-title">Birthday</p>

              <time datetime="1996-12-08">December 8, 1996</time>
            </div>

          </li>

          <li class="contact-item">

            <div class="icon-box">
              <ion-icon name="location-outline"></ion-icon>
            </div>

            <div class="contact-info">
              <p class="contact-title">Location</p>

              <address>Genova, ITALY</address>
            </div>

          </li>

        </ul>

        <div class="separator"></div>

        <ul class="social-list">

          <li class="social-item">
            <a href="https://www.linkedin.com/in/stefano-berti-720217128/" target="_blank" class="social-link">
              <ion-icon name="logo-linkedin"></ion-icon>
            </a>
          </li>

          <li class="social-item">
            <a href="https://www.facebook.com/stefano.berti.75" target="_blank" class="social-link">
              <ion-icon name="logo-facebook"></ion-icon>
            </a>
          </li>

          <li class="social-item">
            <a href="https://www.instagram.com/ste_berti/" target="_blank" class="social-link">
              <ion-icon name="logo-instagram"></ion-icon>
            </a>
          </li>

          <li class="social-item">
            <a href="https://scholar.google.com/citations?user=wJ_9K6UAAAAJ&hl=it&oi=ao" target="_blank" class="social-link">
              <ion-icon name="school-outline"></ion-icon>
            </a>
          </li>

          <li class="social-item">
            <a href="https://www.iit.it/it/people-details/-/people/stefano-berti" target="_blank" class="social-link">
              <ion-icon name="business-outline"></ion-icon>
            </a>
          </li>

          <li class="social-item">
            <a href="https://openreview.net/profile?id=~Stefano_Berti1" target="_blank" class="social-link">
              <ion-icon name="document-text-outline"></ion-icon>
            </a>
          </li>

        </ul>

      </div>

    </aside>





    <!--
      - #main-content
    -->

    <div class="main-content">

      <!--
        - #NAVBAR
      -->

      <nav class="navbar">

        <ul class="navbar-list">

          <li class="navbar-item">
            <button class="navbar-link  active" data-nav-link>About</button>
          </li>

          <li class="navbar-item">
            <button class="navbar-link" data-nav-link>Resume</button>
          </li>

          <li class="navbar-item">
            <button class="navbar-link" data-nav-link>Publications</button>
          </li>

          <li class="navbar-item">
            <button class="navbar-link" data-nav-link>Contact</button>
          </li>

        </ul>

      </nav>





      <!--
        - #ABOUT
      -->

      <article class="about  active" data-page="about">

        <header>
          <h2 class="h2 article-title">About me</h2>
        </header>

        <section class="about-text">
          <p>
            I am a PhD student at the <a href="https://www.iit.it/it/home">Italian Institute of Technology (IIT)</a>,
            working in the <a href="https://hsp.iit.it/">Humanoid Sensing and Perception lab.</a>
          </p>

          <p>
            I have a strong background in computer science and machine learning, with a specialization in computer vision and robotics. 
            My PhD research focuses on enabling robots to adapt their understanding of humans to new environments with minimal supervision, 
            requiring only a few demonstrations.
          </p>
        </section>

        <!--
          - Areas of Specialization
        -->
        <section class="specialization">
          <h3 class="h3 section-title">Areas of Specialization</h3>
          <div class="specialization-list">
            <span class="specialization-item">Deep Learning</span>
            <span class="specialization-item">Robotic Vision</span>
            <span class="specialization-item">Human-Robot Interaction</span>
            <span class="specialization-item">Few-Shot Learning</span>
            <span class="specialization-item">Open-Set Recognition</span>
            <span class="specialization-item">Action Recognition</span>
            <span class="specialization-item">Vision-Language Model Personalization</span>
            <span class="specialization-item">Music Generation</span>
          </div>
        </section>

        <!--
          - Technical Knowledge
        -->
        <section class="technical-skills">
          <h3 class="h3 section-title">Technical Knowledge</h3>
          <ul class="skills-list">
            <li class="skill-item">
              <div class="skill-title-wrapper">
                <h5 class="h5 skill-title">PyTorch</h5>
              </div>
            </li>
            <li class="skill-item">
              <div class="skill-title-wrapper">
                <h5 class="h5 skill-title">Git</h5>
              </div>
            </li>
            <li class="skill-item">
              <div class="skill-title-wrapper">
                <h5 class="h5 skill-title">Pandas</h5>
              </div>
            </li>
            <li class="skill-item">
              <div class="skill-title-wrapper">
                <h5 class="h5 skill-title">OpenCV</h5>
              </div>
            </li>
            <li class="skill-item">
              <div class="skill-title-wrapper">
                <h5 class="h5 skill-title">SLURM</h5>
              </div>
            </li>
            <li class="skill-item">
              <div class="skill-title-wrapper">
                <h5 class="h5 skill-title">Docker</h5>
              </div>
            </li>
            <li class="skill-item">
              <div class="skill-title-wrapper">
                <h5 class="h5 skill-title">Conda</h5>
              </div>
            </li>
            <li class="skill-item">
              <div class="skill-title-wrapper">
                <h5 class="h5 skill-title">TensorRT</h5>
              </div>
            </li>
            <li class="skill-item">
              <div class="skill-title-wrapper">
                <h5 class="h5 skill-title">Ubuntu</h5>
              </div>
            </li>
            <li class="skill-item">
              <div class="skill-title-wrapper">
                <h5 class="h5 skill-title">VS Code</h5>
              </div>
            </li>
            <li class="skill-item">
              <div class="skill-title-wrapper">
                <h5 class="h5 skill-title">PyCharm</h5>
              </div>
            </li>
          </ul>
        </section>

        <!--
          - Additional Information
        -->
        <section class="additional-info">
          <div class="info-grid">
            <div class="info-section">
              <h3 class="h3 section-title">Attended Conferences</h3>
              <ul class="conference-list">
                <li class="conference-item">
                  <span class="conference-year">2024</span>
                  <span class="conference-name">ECCV</span>
                </li>
                <li class="conference-item">
                  <span class="conference-year">2024</span>
                  <span class="conference-name">CVPR</span>
                </li>
                <li class="conference-item">
                  <span class="conference-year">2023</span>
                  <span class="conference-name">ICRA</span>
                </li>
                <li class="conference-item">
                  <span class="conference-year">2022</span>
                  <span class="conference-name">Humanoids</span>
                </li>
                <li class="conference-item">
                  <span class="conference-year">2021</span>
                  <span class="conference-name">ESANN</span>
                </li>
              </ul>
            </div>

            <div class="info-section">
              <h3 class="h3 section-title">Languages</h3>
              <ul class="language-list">
                <li class="language-item">
                  <div class="language-info">
                    <span class="language-name">Italian</span>
                    <span class="language-level">C2</span>
                  </div>
                  <span class="language-note">Mother tongue</span>
                </li>
                <li class="language-item">
                  <div class="language-info">
                    <span class="language-name">English</span>
                    <span class="language-level">C2</span>
                  </div>
                  <div class="language-proficiency">
                    <span class="proficiency-dot active"></span>
                    <span class="proficiency-dot active"></span>
                    <span class="proficiency-dot active"></span>
                    <span class="proficiency-dot active"></span>
                    <span class="proficiency-dot"></span>
                  </div>
                </li>
              </ul>
            </div>
          </div>
        </section>

      </article>





      <!--
        - #RESUME
      -->

      <article class="resume" data-page="resume">

        <header>
          <h2 class="h2 article-title">Resume</h2>
        </header>

        <section class="timeline">

          <div class="title-wrapper">
            <div class="icon-box">
              <ion-icon name="book-outline"></ion-icon>
            </div>

            <h3 class="h3">Education</h3>
          </div>

          <ol class="timeline-list">

            <li class="timeline-item">

              <h4 class="h4 timeline-item-title">Master Degree in Artificial Intelligence</h4>

              <span>2018 — 2021</span>

              <p class="timeline-text">
                Graduated on time with top marks from University of Pisa, completing a thesis on music generation that leads to a publication.
              </p>

            </li>

            <li class="timeline-item">

              <h4 class="h4 timeline-item-title">Bachelor Degree in Computer Science</h4>

              <span>2015 — 2018</span>

              <p class="timeline-text">
                Graduated on time with top marks and honors from University of Genova.
              </p>

            </li>

          </ol>

        </section>

        <section class="timeline">

          <div class="title-wrapper">
            <div class="icon-box">
              <ion-icon name="book-outline"></ion-icon>
            </div>

            <h3 class="h3">Experience</h3>
          </div>

          <ol class="timeline-list">

            <li class="timeline-item">

              <h4 class="h4 timeline-item-title">Ph.D. Student</h4>

              <span>2022 — Present</span>

              <p class="timeline-text">
                My research focuses on Human-Robot Interaction tasks, including Action Recognition with an emphasis on Few-Shot Learning and Open-Set Detection, Focus Detection, and Human-Pose Estimation. I have applied the outcomes of my research to the iCub and ergoCub robot platforms in various demonstrations.
              </p>

            </li>

          </ol>

        </section>

      </article>





      <!--
        - #PUBLICATIONS
      -->

      <article class="publications" data-page="publications">

        <header>
          <h2 class="h2 article-title">Publications</h2>
        </header>

        <section class="publications-list">

          <ul class="publications-timeline">

            <li class="publication-item" data-publication-item>
              <div class="publication-year">2024</div>
              <div class="publication-image">
                <img src="./assets/images/roman.jpg" alt="ROMAN 2024 Conference" width="80" class="publication-img-clickable" data-popup-img="./assets/images/roman.jpg">
              </div>
              <div class="publication-content">
                <p class="publication-text">
                  <em>The impact of Compositionality in Zero-shot Multi-label action recognition for Object-based tasks.</em> Calabrese Carmela, Berti Stefano et al. 2024 33rd IEEE International Conference on Robot and Human Interactive Communication (ROMAN). IEEE, 2024.
                </p>
                <div class="publication-abstract" style="display: none;">
                  <h5>Abstract</h5>
                  <p>Addressing multi-label action recognition in videos represents a significant challenge for robotic applications in dynamic environments, especially when the robot is required to cooperate with humans in tasks that involve objects. Existing methods still struggle to recognize unseen actions or require extensive training data. To overcome these problems, we propose Dual-VCLIP, a unified approach for zero-shot multi-label action recognition. Dual-VCLIP enhances VCLIP, a zero-shot action recognition method, with the DualCoOp method for multi-label image classification. The strength of our method is that at training time it only learns two prompts, and it is therefore much simpler than other methods. We validate our method on the Charades dataset that includes a majority of object-based actions, demonstrating that - despite its simplicity - our method performs favorably with respect to existing methods on the complete dataset, and promising performance when tested on unseen actions. Our contribution emphasizes the impact of verb-object class-splits during robots' training for new cooperative tasks, highlighting the influence on the performance and giving insights into mitigating biases. Dataset splits and code are publicly available on the project's repository.</p>
                  <p><strong>Conference:</strong> IEEE International Conference on Robot and Human Interactive Communication (ROMAN)</p>
                  <p><strong>Keywords:</strong> Action Recognition, Zero-shot Learning, Multi-label Classification, Human-Robot Interaction</p>
                  
                  <div class="publication-links">
                    <a href="https://ieeexplore.ieee.org/abstract/document/10731472/?casa_token=WVCLeYpG4vsAAAAA:wTZeVaNftzYDWAnkcyeMZxSRiHcnmFbGOWwAjeygyuP2lSqYGEdpySvCpmIIcMlarmyd_JnVpdKmnQ" target="_blank" class="arxiv-btn">
                      <ion-icon name="document-text-outline"></ion-icon>
                      IEEE Paper
                    </a>
                    <a href="https://github.com/hsp-iit/DualVCLIP" target="_blank" class="arxiv-btn">
                      <ion-icon name="logo-github"></ion-icon>
                      Code
                    </a>
                  </div>
                </div>
              </div>
              <div class="publication-expand-btn">
                <ion-icon name="chevron-down-outline"></ion-icon>
              </div>
            </li>

            <li class="publication-item" data-publication-item>
              <div class="publication-year">2023</div>
              <div class="publication-image">
                <img src="./assets/images/concon-chi.png" alt="CVPR 2023 Conference" width="80" class="publication-img-clickable" data-popup-img="./assets/images/concon-chi.png">
              </div>
              <div class="publication-content">
                <p class="publication-text">
                  <em>ConCon-Chi: Concept-Context Chimera Benchmark for Personalized Vision-Language Tasks</em>, Rosasco Andrea, Berti Stefano, Pasquale Giulia et al. 2023 IEEE-RAS 22nd International Conference on Computer Vision and Pattern Recognition (CVPR). IEEE 2023
                </p>
                <div class="publication-abstract" style="display: none;">
                  <h5>Abstract</h5>
                  <p>While recent Vision-Language (VL) models excel at open-vocabulary tasks it is unclear how to use them with specific or uncommon concepts. Personalized Text-to-Image Retrieval (TIR) or Generation (TIG) are recently introduced tasks that represent this challenge where the VL model has to learn a concept from few images and respectively discriminate or generate images of the target concept in arbitrary contexts. We identify the ability to learn new meanings and their compositionality with known ones as two key properties of a personalized system. We show that the available benchmarks offer a limited validation of personalized textual concept learning from images with respect to the above properties and introduce ConCon-Chi as a benchmark for both personalized TIR and TIG designed to fill this gap. We modelled the new-meaning concepts by crafting chimeric objects and formulating a large varied set of contexts where we photographed each object. To promote the compositionality assessment of the learned concepts with known contexts we combined different contexts with the same concept and vice-versa. We carry out a thorough evaluation of state-of-the-art methods on the resulting dataset. Our study suggests that future work on personalized TIR and TIG methods should focus on the above key properties and we propose principles and a dataset for their performance assessment. Dataset: https://doi.org/10.48557/QJ1166 and code: https://github.com/hsp-iit/concon-chi_benchmark.</p>
                  <p><strong>Conference:</strong> IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</p>
                  <p><strong>Keywords:</strong> Vision-Language Models, Personalization, Benchmark, Concept Understanding</p>
                  
                  <div class="publication-links">
                    <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Rosasco_ConCon-Chi_Concept-Context_Chimera_Benchmark_for_Personalized_Vision-Language_Tasks_CVPR_2024_paper.html" target="_blank" class="arxiv-btn">
                      <ion-icon name="document-text-outline"></ion-icon>
                      CVPR Paper
                    </a>
                    <a href="https://github.com/hsp-iit/concon-chi_benchmark" target="_blank" class="arxiv-btn">
                      <ion-icon name="logo-github"></ion-icon>
                      Code
                    </a>
                  </div>
                </div>
              </div>
              <div class="publication-expand-btn">
                <ion-icon name="chevron-down-outline"></ion-icon>
              </div>
            </li>

            <li class="publication-item" data-publication-item>
              <div class="publication-year">2022</div>
              <div class="publication-image">
                <img src="./assets/images/ososskar.png" alt="Humanoids 2022 Conference" width="80" class="publication-img-clickable" data-popup-img="./assets/images/ososskar.png">
              </div>
              <div class="publication-content">
                <p class="publication-text">
                  <em>One-shot open-set skeleton-based action recognition</em>, Berti Stefano, et al. 2022 IEEE-RAS 21st International Conference on Humanoid Robots (Humanoids). IEEE, 2022.
                </p>
                <div class="publication-abstract" style="display: none;">
                  <h5>Abstract</h5>
                  <p>Action recognition is a fundamental capability for humanoid robots to interact and cooperate with humans. This application requires the action recognition system to be designed so that new actions can be easily added, while "unknown" actions are identified and ignored. In recent years, deep-learning approaches represented the principal solution to the Action Recognition problem. However, most models often require a large dataset of manually-labeled samples. In this work we target One-Shot deep-learning models, because they can deal with just a single instance for class. Unfortunately, One-Shot models assume that, at inference time, the action to recognize falls into the support set and they fail when the action lies outside the support set. Few-Shot Open-Set Recognition (FSOSR) solutions attempt to address that flaw, but current solutions consider only static images and not sequences of images. Static images remain insufficient to discriminate actions such as sitting-down and standing-up. In this paper we propose a novel model that addresses the FSOSR problem with a One-Shot model that is augmented with a discriminator that rejects "unknown" actions. This model is useful for applications in humanoid robotics, because it allows to easily add new classes and determine whether an input sequence is among the ones that are known to the system. We show how to train the whole model in an end-to-end fashion and we perform quantitative and qualitative analyses. Finally, we provide real-world examples.</p>
                  <p><strong>Conference:</strong> IEEE-RAS International Conference on Humanoid Robots (Humanoids)</p>
                  <p><strong>Keywords:</strong> One-shot Learning, Open-set Recognition, Skeleton-based Action Recognition, Few-shot Learning</p>
                  
                  <div class="publication-links">
                    <a href="https://ieeexplore.ieee.org/abstract/document/10000115?casa_token=0-qpiST04ccAAAAA:2cJu3ducfdQXvqI3GW9UQ_g64lli_iXsvDtF8KXQfaHh5zxBEwT5Wdqo3r8q2UBxs0n-KhR_mQNccg" target="_blank" class="arxiv-btn">
                      <ion-icon name="document-text-outline"></ion-icon>
                      IEEE Paper
                    </a>
                    <a href="https://github.com/steb6/ISBFSAR" target="_blank" class="arxiv-btn">
                      <ion-icon name="logo-github"></ion-icon>
                      Code
                    </a>
                  </div>
                </div>
              </div>
              <div class="publication-expand-btn">
                <ion-icon name="chevron-down-outline"></ion-icon>
              </div>
            </li>

            <li class="publication-item" data-publication-item>
              <div class="publication-year">2022</div>
              <div class="publication-image">
                <img src="./assets/images/shape-completion.jpg" alt="Shape Completion Research" width="80" class="publication-img-clickable" data-popup-img="./assets/images/shape-completion.jpg">
              </div>
              <div class="publication-content">
                <p class="publication-text">
                  <em>Towards Confidence-guided Shape Completion for Robotic Applications</em> Rosasco Andrea, et al. 2022 IEEE-RAS 21st International Conference on Humanoid Robots (Humanoids). IEEE, 2022.
                </p>
                <div class="publication-abstract" style="display: none;">
                  <h5>Abstract</h5>
                  <p>Many robotic tasks involving some form of 3D visual perception greatly benefit from a complete knowledge of the working environment. However, robots often have to tackle unstructured environments and their onboard visual sensors can only provide incomplete information due to limited workspaces, clutter or object self-occlusion. In recent years, deep learning architectures for shape completion have begun taking traction as effective means of inferring a complete 3D object representation from partial visual data. Nevertheless, most of the existing state-of-the-art approaches provide a fixed output resolution in the form of voxel grids, strictly related to the size of the neural network output stage. While this is enough for some tasks, e.g. obstacle avoidance in navigation, grasping and manipulation require finer resolutions and simply scaling up the neural network outputs is computationally expensive. In this paper, we address this limitation by proposing an object shape completion method based on an implicit 3D representation providing a confidence value for each reconstructed point. As a second contribution, we propose a gradient-based method for efficiently sampling such implicit function at an arbitrary resolution, tunable at inference time. We experimentally validate our approach by comparing reconstructed shape with ground truth, and by deploying our shape completion algorithm in a robotic grasping pipeline. In both cases, we compare results with a state-of-the-art shape completion approach. The code is available at https://github.com/andrearosasco/hyperpcr.</p>
                  <p><strong>Conference:</strong> IEEE-RAS International Conference on Humanoid Robots (Humanoids)</p>
                  <p><strong>Keywords:</strong> Shape Completion, 3D Reconstruction, Confidence Estimation, Robotic Manipulation</p>
                  
                  <div class="publication-links">
                    <a href="https://ieeexplore.ieee.org/abstract/document/10000218?casa_token=XnfzY8uZA2MAAAAA:DhAU0JHRYy9yvSnbaN7MLwg-5ryeX8117hRN4N0PUylJM9PYnjGfq1ZGf2bjfbbM3fyWpji461xwjA" target="_blank" class="arxiv-btn">
                      <ion-icon name="document-text-outline"></ion-icon>
                      IEEE Paper
                    </a>
                    <a href="https://github.com/andrearosasco/hyperpcr" target="_blank" class="arxiv-btn">
                      <ion-icon name="logo-github"></ion-icon>
                      Code
                    </a>
                  </div>
                </div>
              </div>
              <div class="publication-expand-btn">
                <ion-icon name="chevron-down-outline"></ion-icon>
              </div>
            </li>

            <li class="publication-item" data-publication-item>
              <div class="publication-year">2021</div>
              <div class="publication-image">
                <img src="./assets/images/calliope.png" alt="Calliope - Music Generation Research" width="80" class="publication-img-clickable" data-popup-img="./assets/images/calliope.png">
              </div>
              <div class="publication-content">
                <p class="publication-text">
                  <em>Calliope--A Polyphonic Music Transformer</em>, Valenti Andrea, Stefano Berti, and Davide Bacciu. 2021 IEEE-RAS 20th International Conference on European Summit About Neural Networks (ESANN). IEEE, 2021.
                </p>
                <div class="publication-abstract" style="display: none;">
                  <h5>Abstract</h5>
                  <p>The polyphonic nature of music makes the application of deep learning to music modelling a challenging task. On the other hand, the Transformer architecture seems to be a good fit for this kind of data. In this work, we present Calliope, a novel autoencoder model based on Transformers for the efficient modelling of multi-track sequences of polyphonic music. The experiments show that our model is able to improve the state of the art on musical sequence reconstruction and generation, with remarkably good results especially on long sequences.</p>
                  <p><strong>Conference:</strong> European Summit About Neural Networks (ESANN)</p>
                  <p><strong>Keywords:</strong> Music Generation, Transformer Architecture, Polyphonic Music, Deep Learning</p>
                  
                  <div class="publication-links">
                    <a href="https://arxiv.org/abs/2107.05546" target="_blank" class="arxiv-btn">
                      <ion-icon name="document-text-outline"></ion-icon>
                      ArXiv
                    </a>
                    <a href="https://github.com/steb6/Calliope" target="_blank" class="arxiv-btn">
                      <ion-icon name="logo-github"></ion-icon>
                      Code
                    </a>
                  </div>
                  
                  <!-- MIDI Player Section -->
                  <div class="midi-embed">
                    <button type="button" class="midi-embed-collapsible">� Reconstruction Examples</button>
                    <div class="midi-embed-content">
                      <div class="midi-embed-row">
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Original</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/REC_original.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/REC_original.mid" sound-font controls></midi-player>
                        </div>
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Reconstructed</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/REC_reconstructed.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/REC_reconstructed.mid" sound-font controls></midi-player>
                        </div>
                      </div>
                      <div class="midi-embed-row">
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Original 1</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/REC_original_1.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/REC_original_1.mid" sound-font controls></midi-player>
                        </div>
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Reconstructed 1</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/REC_reconstructed_1.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/REC_reconstructed_1.mid" sound-font controls></midi-player>
                        </div>
                      </div>
                      <div class="midi-embed-row">
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Original 2</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/REC_original_2.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/REC_original_2.mid" sound-font controls></midi-player>
                        </div>
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Reconstructed 2</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/REC_reconstructed_2.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/REC_reconstructed_2.mid" sound-font controls></midi-player>
                        </div>
                      </div>
                      <div class="midi-embed-row">
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Original 3</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/REC_original_3.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/REC_original_3.mid" sound-font controls></midi-player>
                        </div>
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Reconstructed 3</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/REC_reconstructed_3.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/REC_reconstructed_3.mid" sound-font controls></midi-player>
                        </div>
                      </div>
                    </div>
                    
                    <button type="button" class="midi-embed-collapsible">� Generated 2-Bar Songs</button>
                    <div class="midi-embed-content">
                      <div class="midi-embed-row">
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Generated Sample 1</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/2bar_1.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/2bar_1.mid" sound-font controls></midi-player>
                        </div>
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Generated Sample 2</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/2bar_2.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/2bar_2.mid" sound-font controls></midi-player>
                        </div>
                      </div>
                      <div class="midi-embed-row">
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Generated Sample 3</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/2bar_3.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/2bar_3.mid" sound-font controls></midi-player>
                        </div>
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Generated Sample 4</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/2bar_4.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/2bar_4.mid" sound-font controls></midi-player>
                        </div>
                      </div>
                    </div>

                    <button type="button" class="midi-embed-collapsible">🎵 Generated Songs Explorer (100 samples)</button>
                    <div class="midi-embed-content">
                      <div class="gen-explorer-controls">
                        <button type="button" id="prevGenBtn">◀ Previous</button>
                        <span id="genIndexDisplay">Sample 0 / 99</span>
                        <button type="button" id="nextGenBtn">Next ▶</button>
                        <input type="range" id="genSlider" min="0" max="99" value="0" step="1">
                      </div>
                      <div class="midi-embed-row">
                        <div class="midi-embed-item">
                          <div class="midi-embed-label" id="genSampleLabel">Generated Sample 0</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer id="genVisualizer" src="./assets/audio/gen2/GEN_generated_0.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player id="genPlayer" src="./assets/audio/gen2/GEN_generated_0.mid" sound-font controls></midi-player>
                        </div>
                      </div>
                    </div>

                    <button type="button" class="midi-embed-collapsible">🔄 Latent Space Interpolation</button>
                    <div class="midi-embed-content">
                      <div class="midi-embed-row">
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Interpolation 1</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/2bar_int_1.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/2bar_int_1.mid" sound-font controls></midi-player>
                        </div>
                      </div>
                      <div class="midi-embed-row">
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Interpolation 2</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/2bar_int_2.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/2bar_int_2.mid" sound-font controls></midi-player>
                        </div>
                      </div>
                      <div class="midi-embed-row">
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Interpolation 3</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/2bar_int_3.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/2bar_int_3.mid" sound-font controls></midi-player>
                        </div>
                      </div>
                      <div class="midi-embed-row">
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">Interpolation 4</div>
                          <div class="midi-visualizer-wrapper">
                            <midi-visualizer src="./assets/audio/2bar_int_4.mid" type="piano-roll" visualizer-options='{"noteHeight": 4}'></midi-visualizer>
                          </div>
                          <midi-player src="./assets/audio/2bar_int_4.mid" sound-font controls></midi-player>
                        </div>
                      </div>
                    </div>

                    <button type="button" class="midi-embed-collapsible">🎹 16-Bar Audio Comparison</button>
                    <div class="midi-embed-content">
                      <div class="midi-embed-row">
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">16-Bar Original (Audio)</div>
                          <audio controls style="width: 100%; margin: 10px 0;">
                            <source src="./assets/audio/16-bar-original.wav" type="audio/wav">
                            Your browser does not support the audio element.
                          </audio>
                        </div>
                        <div class="midi-embed-item">
                          <div class="midi-embed-label">16-Bar Reconstructed (Audio)</div>
                          <audio controls style="width: 100%; margin: 10px 0;">
                            <source src="./assets/audio/16-bar-reconstructed.wav" type="audio/wav">
                            Your browser does not support the audio element.
                          </audio>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <div class="publication-expand-btn">
                <ion-icon name="chevron-down-outline"></ion-icon>
              </div>
            </li>

          </ul>

        </section>

      </article>





      <!--
        - #CONTACT
      -->

      <article class="contact" data-page="contact">

        <header>
          <h2 class="h2 article-title">Contact</h2>
        </header>

        <section class="mapbox" data-mapbox>
          <figure>
            <iframe
              src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d92282.1392597734!2d8.866909726562498!3d44.41149!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x12d34152dcd49aad%3A0x236a84f11881620a!2sGenova%2C%20Italy!5e0!3m2!1sen!2sit!4v1642608789441!5m2!1sen!2sit"
              width="400" height="300" loading="lazy"></iframe>
          </figure>
        </section>

        <section class="contact-form">

          <h3 class="h3 form-title">Contact Form</h3>

          <form action="#" class="form" data-form>

            <div class="input-wrapper">
              <input type="text" name="fullname" class="form-input" placeholder="Full name" required data-form-input>

              <input type="email" name="email" class="form-input" placeholder="Email address" required data-form-input>
            </div>

            <textarea name="message" class="form-input" placeholder="Your Message" required data-form-input></textarea>

            <button class="form-btn" type="submit" disabled data-form-btn>
              <ion-icon name="paper-plane"></ion-icon>
              <span>Send Message</span>
            </button>

          </form>

        </section>

      </article>

    </div>

  </main>

  <!--
    - image popup modal
  -->
  <div class="image-modal-container" data-image-modal-container>

    <div class="overlay" data-image-overlay></div>

    <section class="image-modal">

      <button class="modal-close-btn" data-image-modal-close-btn>
        <ion-icon name="close-outline"></ion-icon>
      </button>

      <div class="image-modal-content">
        <img src="" alt="" data-popup-modal-img>
      </div>

    </section>

  </div>






  <!--
    - custom js link
  -->
  <script src="./assets/js/script.js?v=2024011302" defer></script>

  <!--
    - ionicon link
  -->
  <script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script>
  <script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script>

</body>

</html>
